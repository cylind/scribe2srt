#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¥å­åˆ†å‰²å™¨æ¨¡å—
å®ç°åŸºäºæ ‡ç‚¹ç¬¦å·ä¼˜å…ˆçº§çš„å¥å­è¾¹ç•Œæ£€æµ‹ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œç‰¹æ®Šç±»å‹å¤„ç†
"""

from typing import Dict, List, Tuple
import re


class SentenceSplitter:
    """
    å¥å­åˆ†å‰²å™¨ç±»
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŸºäºæ ‡ç‚¹ç¬¦å·ä¼˜å…ˆçº§è¿›è¡Œå¥å­è¾¹ç•Œæ£€æµ‹
    2. æ­£ç¡®å¤„ç†spacingç±»å‹çš„ç©ºç™½å­—ç¬¦
    3. è¯†åˆ«å¹¶å•ç‹¬å¤„ç†éŸ³é¢‘äº‹ä»¶
    4. æ”¯æŒå¤šè¯­è¨€ï¼ˆCJKå’ŒLatinï¼‰
    """
    
    def __init__(self, language_code: str = "eng"):
        self.language = language_code[:3]
        self.is_cjk = self._is_cjk_language()
        
        # å®šä¹‰æ ‡ç‚¹ç¬¦å·ä¼˜å…ˆçº§
        if self.is_cjk:
            self.high_priority_punct = ["ã€‚", "ï¼", "ï¼Ÿ"]  # å¥å­ç»“æŸç¬¦
            self.medium_priority_punct = ["ï¼›", "ï¼š"]      # å­å¥ç»“æŸç¬¦
            self.low_priority_punct = ["ï¼Œ", "ã€"]         # çŸ­è¯­åˆ†éš”ç¬¦
        else:
            self.high_priority_punct = [".", "!", "?"]    # å¥å­ç»“æŸç¬¦
            self.medium_priority_punct = [";", ":"]       # å­å¥ç»“æŸç¬¦
            self.low_priority_punct = [","]               # çŸ­è¯­åˆ†éš”ç¬¦
        
        # æ‰€æœ‰åˆ†å‰²æ ‡ç‚¹ç¬¦å·
        self.all_split_punct = (self.high_priority_punct + 
                               self.medium_priority_punct + 
                               self.low_priority_punct)
        
        # éŸ³é¢‘äº‹ä»¶å…³é”®è¯ï¼ˆå¯æ‰©å±•ï¼‰
        self.audio_event_keywords = [
            "music", "sound", "noise", "applause", "laughter",
            "éŸ³ä¹", "éŸ³æ•ˆ", "æŒå£°", "ç¬‘å£°", "èƒŒæ™¯éŸ³",
            "â™ª", "â™«", "â™¬", "â™©", "ğŸµ", "ğŸ¶"
        ]
    
    def _is_cjk_language(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºCJKè¯­è¨€"""
        return self.language in ["zho", "jpn", "kor", "chi", "zh", "ja", "ko"]
    
    def _is_audio_event(self, word_info: Dict) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºéŸ³é¢‘äº‹ä»¶
        
        Args:
            word_info: å•è¯ä¿¡æ¯å­—å…¸
            
        Returns:
            æ˜¯å¦ä¸ºéŸ³é¢‘äº‹ä»¶
        """
        text = word_info.get('text', '').strip().lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éŸ³é¢‘äº‹ä»¶å…³é”®è¯
        for keyword in self.audio_event_keywords:
            if keyword.lower() in text:
                return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯ç¬¦å·ï¼ˆå¯èƒ½æ˜¯éŸ³ä¹ç¬¦å·ï¼‰
        if re.match(r'^[^\w\s]+$', text) and len(text) <= 3:
            return True
            
        return False
    
    def _get_punctuation_priority(self, punct: str) -> int:
        """
        è·å–æ ‡ç‚¹ç¬¦å·çš„ä¼˜å…ˆçº§
        
        Args:
            punct: æ ‡ç‚¹ç¬¦å·
            
        Returns:
            ä¼˜å…ˆçº§ (0=é«˜, 1=ä¸­, 2=ä½, -1=ä¸æ˜¯åˆ†å‰²æ ‡ç‚¹)
        """
        if punct in self.high_priority_punct:
            return 0
        elif punct in self.medium_priority_punct:
            return 1
        elif punct in self.low_priority_punct:
            return 2
        else:
            return -1
    
    def _word_ends_with_split_punct(self, word_info: Dict) -> Tuple[bool, str, int]:
        """
        æ£€æŸ¥å•è¯æ˜¯å¦ä»¥åˆ†å‰²æ ‡ç‚¹ç¬¦å·ç»“å°¾
        
        Args:
            word_info: å•è¯ä¿¡æ¯å­—å…¸
            
        Returns:
            (æ˜¯å¦ä»¥åˆ†å‰²æ ‡ç‚¹ç»“å°¾, æ ‡ç‚¹ç¬¦å·, ä¼˜å…ˆçº§)
        """
        text = word_info.get('text', '').strip()
        if not text:
            return False, "", -1
        
        # æ£€æŸ¥æœ€åä¸€ä¸ªå­—ç¬¦
        last_char = text[-1]
        priority = self._get_punctuation_priority(last_char)
        
        if priority >= 0:
            return True, last_char, priority
        
        return False, "", -1
    
    def _should_split_at_word(self, word_info: Dict, accumulated_words: List[Dict]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨æ­¤å•è¯å¤„åˆ†å‰²å¥å­
        
        Args:
            word_info: å½“å‰å•è¯ä¿¡æ¯
            accumulated_words: å·²ç´¯ç§¯çš„å•è¯åˆ—è¡¨
            
        Returns:
            æ˜¯å¦åº”è¯¥åˆ†å‰²
        """
        # å¦‚æœæ˜¯éŸ³é¢‘äº‹ä»¶ï¼Œåº”è¯¥ç‹¬ç«‹æˆå¥
        if self._is_audio_event(word_info):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä»¥åˆ†å‰²æ ‡ç‚¹ç¬¦å·ç»“å°¾
        has_punct, punct, priority = self._word_ends_with_split_punct(word_info)
        
        if not has_punct:
            return False
        
        # é«˜ä¼˜å…ˆçº§æ ‡ç‚¹ç¬¦å·æ€»æ˜¯åˆ†å‰²
        if priority == 0:
            return True
        
        # ä¸­ä¼˜å…ˆçº§æ ‡ç‚¹ç¬¦å·ï¼šéœ€è¦æœ‰è¶³å¤Ÿçš„å†…å®¹
        if priority == 1:
            if len(accumulated_words) >= 3:  # è‡³å°‘3ä¸ªè¯
                return True
        
        # ä½ä¼˜å…ˆçº§æ ‡ç‚¹ç¬¦å·ï¼šéœ€è¦æ›´å¤šå†…å®¹ä¸”ä¸èƒ½å¤ªé¢‘ç¹åˆ†å‰²
        if priority == 2:
            if len(accumulated_words) >= 5:  # è‡³å°‘5ä¸ªè¯
                # æ£€æŸ¥å‰é¢æ˜¯å¦åˆšåˆšæœ‰è¿‡åˆ†å‰²
                total_chars = sum(len(w.get('text', '')) for w in accumulated_words)
                if total_chars >= 15:  # è‡³å°‘15ä¸ªå­—ç¬¦
                    return True
        
        return False
    
    def split_into_sentence_groups(self, words: List[Dict]) -> List[List[Dict]]:
        """
        å°†å•è¯åˆ—è¡¨åˆ†å‰²æˆå¥å­ç»„
        
        Args:
            words: å•è¯åˆ—è¡¨
            
        Returns:
            å¥å­ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå¥å­ç»„åŒ…å«ä¸€ç»„ç›¸å…³çš„å•è¯
        """
        if not words:
            return []
        
        sentence_groups = []
        current_group = []
        
        for i, word in enumerate(words):
            # è·³è¿‡spacingç±»å‹ï¼Œä½†ä¿ç•™å…¶æ–‡æœ¬å†…å®¹åˆ°å‰ä¸€ä¸ªå•è¯
            if word.get('type') == 'spacing':
                if current_group and word.get('text', '').strip() == '':
                    # å°†ç©ºæ ¼æ·»åŠ åˆ°å‰ä¸€ä¸ªå•è¯çš„æ–‡æœ¬ä¸­
                    if not current_group[-1]['text'].endswith(' '):
                        current_group[-1]['text'] += ' '
                continue
            
            # æ·»åŠ å½“å‰å•è¯åˆ°ç»„ä¸­
            current_group.append(word.copy())
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœ¨æ­¤å¤„åˆ†å‰²
            should_split = self._should_split_at_word(word, current_group[:-1])
            
            # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå•è¯ï¼Œå¼ºåˆ¶åˆ†å‰²
            is_last_word = (i == len(words) - 1)
            
            if should_split or is_last_word:
                if current_group:
                    sentence_groups.append(current_group)
                    current_group = []
        
        # å¤„ç†å‰©ä½™çš„å•è¯
        if current_group:
            sentence_groups.append(current_group)
        
        return sentence_groups
    
    def create_basic_subtitle_entries(self, sentence_groups: List[List[Dict]]) -> List[Dict]:
        """
        ä»å¥å­ç»„åˆ›å»ºåŸºæœ¬å­—å¹•æ¡ç›®
        
        Args:
            sentence_groups: å¥å­ç»„åˆ—è¡¨
            
        Returns:
            åŸºæœ¬å­—å¹•æ¡ç›®åˆ—è¡¨
        """
        basic_entries = []
        
        for group in sentence_groups:
            if not group:
                continue
            
            # æå–å®é™…å•è¯ï¼ˆéspacingç±»å‹ï¼‰
            actual_words = [w for w in group if w.get('type') == 'word']
            
            if not actual_words:
                continue
            
            # æ„å»ºæ–‡æœ¬
            text = "".join(w['text'] for w in group).strip()
            
            if not text:
                continue
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = actual_words[0]['start']
            end_time = actual_words[-1]['end']
            
            # åˆ›å»ºåŸºæœ¬æ¡ç›®
            entry = {
                'text': text,
                'start': start_time,
                'end': end_time,
                'words': group,
                'is_audio_event': any(self._is_audio_event(w) for w in group),
                'word_count': len(actual_words),
                'char_count': len(text.replace(' ', ''))  # ä¸è®¡ç©ºæ ¼çš„å­—ç¬¦æ•°
            }
            
            basic_entries.append(entry)
        
        return basic_entries
    
    def analyze_split_quality(self, sentence_groups: List[List[Dict]]) -> Dict:
        """
        åˆ†æåˆ†å‰²è´¨é‡
        
        Args:
            sentence_groups: å¥å­ç»„åˆ—è¡¨
            
        Returns:
            åˆ†å‰²è´¨é‡åˆ†æç»“æœ
        """
        if not sentence_groups:
            return {'total_groups': 0, 'avg_words_per_group': 0, 'punct_endings': 0}
        
        total_groups = len(sentence_groups)
        total_words = sum(len(group) for group in sentence_groups)
        avg_words_per_group = total_words / total_groups if total_groups > 0 else 0
        
        # ç»Ÿè®¡ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾çš„ç»„æ•°
        punct_endings = 0
        for group in sentence_groups:
            if group:
                last_word = group[-1]
                has_punct, _, _ = self._word_ends_with_split_punct(last_word)
                if has_punct:
                    punct_endings += 1
        
        punct_ending_rate = punct_endings / total_groups if total_groups > 0 else 0
        
        return {
            'total_groups': total_groups,
            'total_words': total_words,
            'avg_words_per_group': avg_words_per_group,
            'punct_endings': punct_endings,
            'punct_ending_rate': punct_ending_rate
        }
